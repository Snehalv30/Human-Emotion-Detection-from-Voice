# ğŸ¤ Human Emotion Detection From Voice

An AI-based mini project that detects human emotions from speech audio using Machine Learning and Audio Signal Processing. The system analyzes short voice clips and predicts emotions such as **Angry, Calm, Disgust, Fearful, Happy, Neutral, Sad, and Surprised** with probability scores and visual insights.

---

## ğŸ“Œ Project Overview

Human emotions play a crucial role in communication. This project uses **audio feature extraction** and a **trained ML model** to identify the speaker's emotional state from voice recordings.

The application is built with:

* **Python** for backend & ML
* **Librosa** for audio feature extraction
* **Scikit-learn** for model training
* **Streamlit** for an interactive web interface

---

## âœ¨ Features

* ğŸ§ Upload WAV/MP3 audio files
* ğŸ” Automatic emotion prediction
* ğŸ“Š Emotion probability breakdown
* ğŸ“ˆ Radar chart visualization of emotions
* ğŸŒŠ Audio waveform display
* âš¡ Fast and lightweight Streamlit UI
* ğŸ§  ML-based classification model

---

## ğŸ§  Emotions Supported

* Angry
* Calm
* Disgust
* Fearful
* Happy
* Neutral
* Sad
* Surprised

---

## ğŸ—‚ï¸ Project Structure

```
Human_Emotion_Detection_From_Voice/
â”‚
â”œâ”€â”€ app.py                 # Streamlit application
â”œâ”€â”€ train_model.py         # Model training script
â”œâ”€â”€ models/                # Saved trained model
â”œâ”€â”€ data/                  # Dataset (audio files)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # Project documentation
â””â”€â”€ .venv/                 # Virtual environment (optional)
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/Human_Emotion_Detection_From_Voice.git
cd Human_Emotion_Detection_From_Voice
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv .venv
source .venv/bin/activate   # On Windows: .venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the Application

```bash
streamlit run app.py
```

Open your browser and go to:

```
http://localhost:8501
```

---

## ğŸ§ª How It Works

1. User uploads an audio file (WAV/MP3)
2. Audio is preprocessed and trimmed
3. Features extracted:

   * MFCC
   * Chroma
   * Mel Spectrogram
4. ML model predicts emotion probabilities
5. Results are visualized in charts and tables

---

## ğŸ“Š Output

* Predicted dominant emotion
* Emotion confidence percentages
* Radar chart visualization
* Audio waveform preview

---

## ğŸ“¦ Dataset Used

* RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)

> Note: Dataset is used for educational purposes only.

---

## ğŸš€ Future Enhancements

* ğŸ™ï¸ Live microphone emotion detection
* ğŸ¤– Deep Learning (CNN/LSTM) model
* ğŸŒ Cloud deployment (Streamlit Cloud / HuggingFace)
* ğŸ“ Emotion history & analytics
* ğŸ§¾ Downloadable emotion reports

---

## ğŸ“ Use Cases

* Academic mini/final year projects
* Human-computer interaction systems
* Mental health analysis (research)
* Call center sentiment analysis
* AI-based voice assistants

---

## ğŸ‘¨â€ğŸ’» Author

**Snehal Kedar**
AI & Machine Learning Enthusiast

---

## ğŸ“œ License

This project is for **educational and academic use only**.

---

â­ If you like this project, feel free to star the repository!
